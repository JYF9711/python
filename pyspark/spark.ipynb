{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext( 'local', 'mywordcount')\n",
    "textFile = sc.textFile(\"file:///opt/text/python/pyspark/data.txt\")\n",
    "wordCount = textFile.flatMap(lambda line: line.split(\" \")).map(lambda word: (word,1)).reduceByKey(lambda a, b : a + b)\n",
    "wordCount.collect()\n",
    "wordCount.foreach(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD综合应用 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "随即生成年龄\n",
    "agegenerate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "for i in range(10):\n",
    "    num=rd.random()*100\n",
    "    str1=str(i)+ \" \"+str(int(num))\n",
    "    print(str1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "新建age.txt,内容为以上结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD操作计算平均年龄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由年龄文件生成人rdd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext( 'local', 'mywordcount')\n",
    "rdd1=sc.textFile(\"age.txt\")\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD转换（年龄，1）形式的RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd2 = rdd1.map(lambda line : line.split(\" \")).map(lambda x:(int(x[1]),1))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd2.keys().reduce(lambda x,y : x+y)/rdd2.values().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"spark\",2),(\"hadoop\",6),(\"hadoop\",4),(\"spark\",6)])\n",
    "rdd.mapValues(lambda x : (x,1)).reduceByKey(lambda x,y : (x[0]+y[0],x[1] + y[1])).mapValues(lambda x : (x[0] / x[1])).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd=sc.parallelize([\"b\",\"a\",\"c\"])\n",
    "rdd.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd.unpersist()\n",
    "rdd.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验四---SparkDataFram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='序号,书名,评分,价格,出版社,url'),\n",
       " Row(value='5173,動力取向精神醫學--臨床應用與實務,10.0 ,1200元,心灵工坊,https://book.douban.com/subject/6053667/'),\n",
       " Row(value='9929,水彩绘森活,10.0 ,29.8,人民邮电出版社,https://book.douban.com/subject/26115807/'),\n",
       " Row(value='10124,殷周金文集成(修订增补本共8册)(精),10.0 ,2400.00元,中华书局,https://book.douban.com/subject/2235855/'),\n",
       " Row(value='16628,纸雕游戏大书,10.0 ,99.00元,重庆出版集团,https://book.douban.com/subject/26673804/')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"rddDataFrame\").master(\"local[*]\").getOrCreate()\n",
    "#读取数据\n",
    "book=spark.read.text('file:///opt/text/python/pyspark/book.txt')\n",
    "book.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "将book的DataFrame转化RDD操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='序号', name='书名', rating='评分', price='价格', publish='出版社', rul='url'),\n",
       " Row(id='5173', name='動力取向精神醫學--臨床應用與實務', rating='10.0 ', price='1200元', publish='心灵工坊', rul='https://book.douban.com/subject/6053667/'),\n",
       " Row(id='9929', name='水彩绘森活', rating='10.0 ', price='29.8', publish='人民邮电出版社', rul='https://book.douban.com/subject/26115807/'),\n",
       " Row(id='10124', name='殷周金文集成(修订增补本共8册)(精)', rating='10.0 ', price='2400.00元', publish='中华书局', rul='https://book.douban.com/subject/2235855/'),\n",
       " Row(id='16628', name='纸雕游戏大书', rating='10.0 ', price='99.00元', publish='重庆出版集团', rul='https://book.douban.com/subject/26673804/')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_rdd=book.rdd.map(lambda x:x[0].split(\",\")).map(lambda x:Row(id=x[0],name=x[1],rating=x[2],price=x[3],publish=x[4],rul=x[5]))\n",
    "book_rdd.take(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "创建dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------+------+---------+--------------+--------------------+\n",
      "|   id|                             name|rating|    price|       publish|                 rul|\n",
      "+-----+---------------------------------+------+---------+--------------+--------------------+\n",
      "| 序号|                             书名|  评分|     价格|        出版社|                 url|\n",
      "| 5173| 動力取向精神醫學--臨床應用與實務| 10.0 |   1200元|      心灵工坊|https://book.doub...|\n",
      "| 9929|                       水彩绘森活| 10.0 |     29.8|人民邮电出版社|https://book.doub...|\n",
      "|10124|殷周金文集成(修订增补本共8册)(精)| 10.0 |2400.00元|      中华书局|https://book.doub...|\n",
      "|16628|                     纸雕游戏大书| 10.0 |  99.00元|  重庆出版集团|https://book.doub...|\n",
      "+-----+---------------------------------+------+---------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_df=spark.createDataFrame(book_rdd)\n",
    "book_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- publish: string (nullable = true)\n",
      " |-- rul: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------+\n",
      "|   id|                               name|\n",
      "+-----+-----------------------------------+\n",
      "| 序号|                               书名|\n",
      "| 5173|   動力取向精神醫學--臨床應用與實務|\n",
      "| 9929|                         水彩绘森活|\n",
      "|10124|  殷周金文集成(修订增补本共8册)(精)|\n",
      "|16628|                       纸雕游戏大书|\n",
      "|19103|                       Michelangelo|\n",
      "|20063|                  一支笔的快乐涂鸦2|\n",
      "|32781|                         亲亲宝贝装|\n",
      "|32879|                     Photoshop7解像|\n",
      "|45687|                   戚蓼生序本石头记|\n",
      "|52504|                      宇宙兄弟（7）|\n",
      "|52505|                      宇宙兄弟（8）|\n",
      "|  573|            TCP\\IP详解（卷1英文版）|\n",
      "|  589|计算机程序设计艺术卷1：基本算法(...|\n",
      "| 5522|         微积分和数学分析引论-第1卷|\n",
      "| 5547|               PrinciplesofNeura...|\n",
      "| 7443|           奈特人体神经解剖彩色图谱|\n",
      "| 8703|                 数学、科学和认识论|\n",
      "| 9924|                       零基础学素描|\n",
      "| 9926|     黑白花意3：300例超写实的花之绘|\n",
      "+-----+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#指定列输出\n",
    "book_df.select('id','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_collect_as_arrow',\n",
       " '_jcols',\n",
       " '_jdf',\n",
       " '_jmap',\n",
       " '_jseq',\n",
       " '_lazy_rdd',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_schema',\n",
       " '_sort_cols',\n",
       " '_support_repr_html',\n",
       " '_to_corrected_pandas_type',\n",
       " 'agg',\n",
       " 'alias',\n",
       " 'approxQuantile',\n",
       " 'cache',\n",
       " 'checkpoint',\n",
       " 'coalesce',\n",
       " 'colRegex',\n",
       " 'collect',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'createGlobalTempView',\n",
       " 'createOrReplaceGlobalTempView',\n",
       " 'createOrReplaceTempView',\n",
       " 'createTempView',\n",
       " 'crossJoin',\n",
       " 'crosstab',\n",
       " 'cube',\n",
       " 'describe',\n",
       " 'distinct',\n",
       " 'drop',\n",
       " 'dropDuplicates',\n",
       " 'drop_duplicates',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'exceptAll',\n",
       " 'explain',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'foreach',\n",
       " 'foreachPartition',\n",
       " 'freqItems',\n",
       " 'groupBy',\n",
       " 'groupby',\n",
       " 'head',\n",
       " 'hint',\n",
       " 'inputFiles',\n",
       " 'intersect',\n",
       " 'intersectAll',\n",
       " 'isLocal',\n",
       " 'isStreaming',\n",
       " 'is_cached',\n",
       " 'join',\n",
       " 'limit',\n",
       " 'localCheckpoint',\n",
       " 'mapInPandas',\n",
       " 'na',\n",
       " 'orderBy',\n",
       " 'persist',\n",
       " 'printSchema',\n",
       " 'randomSplit',\n",
       " 'rdd',\n",
       " 'registerTempTable',\n",
       " 'repartition',\n",
       " 'repartitionByRange',\n",
       " 'replace',\n",
       " 'rollup',\n",
       " 'sameSemantics',\n",
       " 'sample',\n",
       " 'sampleBy',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'selectExpr',\n",
       " 'semanticHash',\n",
       " 'show',\n",
       " 'sort',\n",
       " 'sortWithinPartitions',\n",
       " 'sql_ctx',\n",
       " 'stat',\n",
       " 'storageLevel',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'toDF',\n",
       " 'toJSON',\n",
       " 'toLocalIterator',\n",
       " 'toPandas',\n",
       " 'transform',\n",
       " 'union',\n",
       " 'unionAll',\n",
       " 'unionByName',\n",
       " 'unpersist',\n",
       " 'where',\n",
       " 'withColumn',\n",
       " 'withColumnRenamed',\n",
       " 'withWatermark',\n",
       " 'write',\n",
       " 'writeStream',\n",
       " 'writeTo']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看方法和属性\n",
    "dir(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------+------------+\n",
      "|   id|                               name|(rating - 1)|\n",
      "+-----+-----------------------------------+------------+\n",
      "| 序号|                               书名|        null|\n",
      "| 5173|   動力取向精神醫學--臨床應用與實務|         9.0|\n",
      "| 9929|                         水彩绘森活|         9.0|\n",
      "|10124|  殷周金文集成(修订增补本共8册)(精)|         9.0|\n",
      "|16628|                       纸雕游戏大书|         9.0|\n",
      "|19103|                       Michelangelo|         9.0|\n",
      "|20063|                  一支笔的快乐涂鸦2|         9.0|\n",
      "|32781|                         亲亲宝贝装|         9.0|\n",
      "|32879|                     Photoshop7解像|         9.0|\n",
      "|45687|                   戚蓼生序本石头记|         9.0|\n",
      "|52504|                      宇宙兄弟（7）|         9.0|\n",
      "|52505|                      宇宙兄弟（8）|         9.0|\n",
      "|  573|            TCP\\IP详解（卷1英文版）|         8.9|\n",
      "|  589|计算机程序设计艺术卷1：基本算法(...|         8.9|\n",
      "| 5522|         微积分和数学分析引论-第1卷|         8.9|\n",
      "| 5547|               PrinciplesofNeura...|         8.9|\n",
      "| 7443|           奈特人体神经解剖彩色图谱|         8.9|\n",
      "| 8703|                 数学、科学和认识论|         8.9|\n",
      "| 9924|                       零基础学素描|         8.9|\n",
      "| 9926|     黑白花意3：300例超写实的花之绘|         8.9|\n",
      "+-----+-----------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_df.select(book_df['id'],book_df['name'],book_df['rating']-1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----+\n",
      "|                             publish|count|\n",
      "+------------------------------------+-----+\n",
      "|                         SearchPress|    3|\n",
      "|                McGraw-HillScienc...|    6|\n",
      "|                            上海教育|    5|\n",
      "|                ScholasticPaperbacks|    2|\n",
      "|                                 DAW|    1|\n",
      "|                         PanBooksLtd|    1|\n",
      "|                  奇幻基地出版事業部|    1|\n",
      "|                               Ember|    1|\n",
      "|                         Allyn&Bacon|    1|\n",
      "|                     WalkerArtCenter|    1|\n",
      "|          电子社博文视点资讯有限公司|    1|\n",
      "|上海文艺出版总社，上海锦绣文章出版社|    1|\n",
      "|                          华中理工大|    1|\n",
      "|                            湖北科技|    7|\n",
      "|                       Digireads.com|    2|\n",
      "|                          林白出版社|    6|\n",
      "|                    HODDER&STOUGHTON|    1|\n",
      "|                      北京：三联书店|    1|\n",
      "|                        上海外语教育|    1|\n",
      "|                            揚智文化|    1|\n",
      "+------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "book_pds=book_df.groupBy('publish').count()\n",
    "print(book_pds.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  publish  count\n",
      "0                             SearchPress      3\n",
      "1     McGraw-HillScience/Engineering/Math      6\n",
      "2                                    上海教育      5\n",
      "3                    ScholasticPaperbacks      2\n",
      "4                                     DAW      1\n",
      "...                                   ...    ...\n",
      "4010                                 学苑出版      1\n",
      "4011                                 青森文化      1\n",
      "4012                                中国福利会      1\n",
      "4013                       第1版(1999年1月1日)      1\n",
      "4014           MacmillanU.K.;NewEdedition      1\n",
      "\n",
      "[4015 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "book_pds=book_pds.toPandas()\n",
    "print(book_pds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-192769916315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbook_pds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'publish'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'book count of publish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0mplot_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_plot_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         x, y, kind, kwargs = self._get_call_args(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1786\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m   1787\u001b[0m                 \u001b[0;34m\"matplotlib is required for plotting when the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m                 \u001b[0;34m'default backend \"matplotlib\" is selected.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "ax=book_pds.head(n=10).plot(x='publish',y=['count'],kind='bar',title='book count of publish')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark=SparkSession.builder.appName(\"rddDataFrame\").master(\"local[*]\").getOrCreate()\n",
    "#读取数据\n",
    "book=spark.read.text('file:///opt/text/python/pyspark/book.txt')\n",
    "#转化Rdd\n",
    "book_rdd=book.rdd.map(lambda x:x[0].split(\",\")).map(lambda x:Row(id=x[0],name=x[1],rating=x[2],price=x[3],publish=x[4],rul=x[5]))\n",
    "#创建dataFrame\n",
    "book_df=spark.createDataFrame(book_rdd)\n",
    "# book_df.select(book_df['id'],book_df['name'],book_df['rating']-1).show()\n",
    "#pandas\n",
    "book_pds=book_df.groupBy('publish').count()\n",
    "book_pds=book_pds.toPandas()\n",
    "ax=book_pds.head(n=10).plot(x='publish',y=['count'],kind='bar',title='book count of publish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验五"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark=SparkSession.builder.appName(\"rddDataFrame\").master(\"local[*]\").getOrCreate()\n",
    "#读取数据\n",
    "book=spark.read.text('file:///opt/text/python/pyspark/book.txt')\n",
    "#rdd\n",
    "book_rdd=book.rdd.map(lambda x:x[0].split(\",\")).map(lambda \\ x:Row(id=x[0],name=x[1],rating=x[2],price=x[3],publish=x[4],url=x[5]))\n",
    "#dataframe\n",
    "book_df=spark.createDataFrame(book_rdd)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
